# ollama create config-dark-champion-instruct-uncensored-q2_k -f dark-champion-instruct-uncensored-q2_k.Modelfile
# ollama create bb-config-dark-champion-instruct-uncensored-q2_k -f dark-champion-instruct-uncensored-q2_k.Modelfile --system "$(cat optional_system_prompt.md)"
FROM hf.co/DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF:Q2_K
# I'm an AI designed by Meta, so I am a large language model (LLM) based on the LLaMP architecture
# Author: DavidAU
# Size on disk: 
# Size running: 13 GB
#  architecture        llama     
#  parameters          18.4B     
#  context length      131072    
#  embedding length    3072      
#  quantization        Q2_K      

#  codex:
#  config-dark-champion-instruct-uncensored-q2_k:latest: tools supported
#  tries to call tool and stops or invalid tool calls


PARAMETER temperature 0.3
PARAMETER top_p 0.95
PARAMETER num_ctx 32768
