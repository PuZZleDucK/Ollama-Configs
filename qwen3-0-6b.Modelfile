# ollama create config-qwen3-0-6b -f qwen3-0-6b.Modelfile
# ollama create bb-config-qwen3-0-6b -f qwen3-0-6b.Modelfile --system "$(cat optional_system_prompt.md)"
FROM qwen3:0.6b
# I am not an LLM model; I am a large language model designed to assist with tasks like answering questions
# Author: Alibaba (Qwen Team)
# Size on disk: 
# Size running: 7.4 GB
#  architecture        qwen3      
#  parameters          751.63M    
#  context length      40960      
#  embedding length    1024       
#  quantization        Q4_K_M     

#  codex:
#  config-qwen3-0-6b:latest: tools supported
#  no tool calls

PARAMETER temperature 0.7
PARAMETER top_p 0.8
PARAMETER repeat_penalty 1.05
PARAMETER num_ctx 131072
PARAMETER top_k 20
PARAMETER min_p 0.0
PARAMETER presence_penalty 1.5
