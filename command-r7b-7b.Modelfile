# ollama create config-command-r7b-7b -f config-command-r7b-7b.Modelfile
# ollama create bb-config-command-r7b-7b -f config-command-r7b-7b.Modelfile --system "$(cat optional_system_prompt.md)"
FROM command-r7b:7b
#  I am Command, a sophisticated large language model developed by Cohere
# Size on disk: 5.1 GB on disk
# Size running: 7.5 GB running
#  architecture        cohere2    
#  parameters          8.0B       
#  context length      8192       ???
#  embedding length    4096       
#  quantization        Q4_K_M

PARAMETER num_predict 100
PARAMETER temperature 0.3
PARAMETER stop "<|START_OF_TURN_TOKEN|>"
PARAMETER stop "<|END_OF_TURN_TOKEN|>"
PARAMETER stop "<|END_RESPONSE|>"
PARAMETER num_ctx 131072
PARAMETER top_k 40
PARAMETER top_p 0.95
PARAMETER min_p 0.05
PARAMETER typical_p 1.0

#  SYSTEM You are a concise coding assistant.
#  TEMPLATE """{{ if .System }}{{ .System }} {{ end }}<!-- original --> {{ .Prompt }}"""
#    #  • {{ .System }} – the system prompt (may be empty)
#    #  • {{ .Prompt }} – the user prompt (single‑turn generate) or the last user message (chat)
#    #  • {{ .Messages }} / {{ range .Messages }} – an array of all prior chat turns (only when you call /api/chat)
#    #  • {{ .Response }} – marker indicating where the model’s answer should start (everything after it is thrown away during generation).
#    #  Wrap sections with {{ if .System }} … {{ end }} or {{ if .Prompt }} so the block disappears when the variable is empty.
