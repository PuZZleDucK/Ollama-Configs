# ollama create config-granite4-tiny-h -f granite4-tiny-h.Modelfile
# ollama create bb-config-granite4-tiny-h -f granite4-tiny-h.Modelfile --system "$(cat optional_system_prompt.md)"
FROM granite4:tiny-h
# I am a language model trained by researchers and engineers at IBM for generating human-like text based on the input I receive
# Author: 
# Size on disk: 
# Size running: 8.6 GB    100% GPU
# ollama show config-granite4-tiny-h && ollama run config-granite4-tiny-h "what llm model are you"
#  architecture        granitehybrid    
#  parameters          6.9B             
#  context length      1048576          
#  embedding length    1536             
#  quantization        Q4_K_M           
PARAMETER num_ctx 148576
# 1M context
