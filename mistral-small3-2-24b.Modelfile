# ollama create config-mistral-small3-2-24b -f mistral-small3-2-24b.Modelfile
# ollama create bb-config-mistral-small3-2-24b -f mistral-small3-2-24b.Modelfile --system "$(cat optional_system_prompt.md)"
FROM mistral-small3.2:24b
# I am Mistral Small 3.2, a Large Language Model (LLM) created by Mistral AI, a French startup headquartered in Paris
# Author: Mistral AI
# Size on disk: 15 GB
# Size running: 34 GB
#  architecture        mistral3    
#  parameters          24.0B       
#  context length      131072      
#  embedding length    5120        
#  quantization        Q4_K_M      

# roo:
#  did call an agent but went haywire
#  made a game window in second run
#  orchestrator seems quite careful
#  agents often read files for context
#  often experience issues but carry on
#  omg... it works... collision detection not working tho
#  movment too fast - some systems don't seem to work (dialog, collition, )
#  now it's broken
# roo-html:
#  went off the rails
#  could not condense context
#  only made js


PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER num_predict 4096
PARAMETER num_ctx 32768
