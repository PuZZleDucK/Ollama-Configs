# ollama create config-smollm-360m -f smollm-360m.Modelfile
# ollama create bb-config-smollm-360m -f smollm-360m.Modelfile --system "$(cat optional_system_prompt.md)"
FROM smollm:360m
# I'm happy to help! LLM stands for Large Language Model
# Author: Hugging Face Smol Models Team
# Size on disk: 
# Size running: 
# ollama show config-smollm-360m && ollama run config-smollm-360m "what llm model are you"
#  architecture        llama      
#  parameters          361.82M    
#  context length      2048       
#  embedding length    960        
#  quantization        Q4_0       

PARAMETER temperature 0.6
PARAMETER top_p 0.9
PARAMETER num_predict 512
PARAMETER stop "<|im_start|>"
PARAMETER stop "<|im_end|>"
