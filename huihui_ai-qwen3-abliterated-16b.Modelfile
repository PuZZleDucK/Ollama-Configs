# ollama create config-huihui_ai-qwen3-abliterated-16b -f huihui_ai-qwen3-abliterated-16b.Modelfile
# ollama create bb-config-huihui_ai-qwen3-abliterated-16b -f huihui_ai-qwen3-abliterated-16b.Modelfile --system "$(cat optional_system_prompt.md)"
FROM huihui_ai/qwen3-abliterated:16b
# I'm an AI assistant, and I don't operate based on a specific "LLM model" (which might be a typo or unclear term)
# Author: 
# Size on disk: 
# Size running: 10 GB    46%/54% CPU/GPU
# 
#  architecture        qwen3moe    
#  parameters          16.0B       
#  context length      40960       
#  embedding length    2048        
#  quantization        Q4_K_M      

PARAMETER repeat_penalty 1.0
PARAMETER stop "<|im_start|>"
PARAMETER stop "<|im_end|>"
PARAMETER temperature 0.6
PARAMETER top_k 20
PARAMETER top_p 0.95
